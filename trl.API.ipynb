{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRL API Interface Documentation\n",
    "\n",
    "This notebook documents the programming interface for the **Airline Sentiment Analysis** library. \n",
    "It demonstrates the usage of the high-level `SentimentModel` wrapper and data utilities defined in `trl_utils`.\n",
    "\n",
    "### Supported Model Registry\n",
    "The library is configured to support the following specific Hugging Face repositories:\n",
    "\n",
    "| Model Name | Type | Hub Path |\n",
    "| :--- | :--- | :--- |\n",
    "| **Baseline BERT** | `bert` | `blank4hd/airline-sentiment-bert-baseline` |\n",
    "| **Baseline GPT-2** | `gpt2` | `blank4hd/airline-sentiment-baseline-gpt2-sft` |\n",
    "| **Improved SFT** | `gpt2` | `blank4hd/airline-sentiment-gpt2-improved-sft` |\n",
    "| **DPO (Active)** | `gpt2` | `blank4hd/airline-sentiment-gpt2-dpo-active-learning` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/msml610/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import trl_utils\n",
    "import torch\n",
    "\n",
    "# We filter warnings here to keep the API demonstration clean and readable\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Device Configuration API\n",
    "The library includes a robust device detection mechanism. It automatically prioritizes hardware accelerators in this order:\n",
    "1. **MPS** (Metal Performance Shaders) for Apple Silicon (Mac M1/M2/M3).\n",
    "2. **CUDA** for NVIDIA GPUs.\n",
    "3. **CPU** as a fallback.\n",
    "\n",
    "**Function:** `get_device()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active Computation Device: mps\n"
     ]
    }
   ],
   "source": [
    "device = trl_utils.get_device()\n",
    "print(f\"Active Computation Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Wrapper Interface\n",
    "The core of the API is the `SentimentModel` class. This wrapper abstracts the complexity of switching between **Sequence Classification** (BERT) and **Causal Language Modeling** (GPT-2).\n",
    "\n",
    "### Initialization Contract\n",
    "To load a model, you must specify the repository ID and the model architecture type (`bert` or `gpt2`).\n",
    "\n",
    "```python\n",
    "model = trl_utils.SentimentModel(\n",
    "    repo_id: str,      # The Hugging Face Hub ID\n",
    "    model_type: str,   # 'bert' or 'gpt2'\n",
    "    device: torch.device = None  # Optional override\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BERT Baseline...\n",
      "Loading blank4hd/airline-sentiment-bert-baseline (bert)...\n",
      "Initializing GPT-2 DPO Model...\n",
      "Loading blank4hd/airline-sentiment-gpt2-dpo-active-learning (gpt2)...\n",
      "\n",
      "✅ Models initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Loading the Baseline BERT (Discriminative)\n",
    "print(\"Initializing BERT Baseline...\")\n",
    "bert_api = trl_utils.SentimentModel(\n",
    "    repo_id=\"blank4hd/airline-sentiment-bert-baseline\",\n",
    "    model_type=\"bert\"\n",
    ")\n",
    "\n",
    "# Example 2: Loading the DPO Active Learning Model (Generative)\n",
    "print(\"Initializing GPT-2 DPO Model...\")\n",
    "dpo_api = trl_utils.SentimentModel(\n",
    "    repo_id=\"blank4hd/airline-sentiment-gpt2-dpo-active-learning\",\n",
    "    model_type=\"gpt2\"\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Models initialized successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inference Interface\n",
    "The `predict` method provides a unified output format regardless of the underlying model architecture. \n",
    "\n",
    "For **BERT**, it calculates the softmax probability of the target class.\n",
    "For **GPT-2**, it constructs a prompt, generates a completion, and parses the resulting token.\n",
    "\n",
    "**Method:** `predict(text: str)`  \n",
    "**Returns:** `Tuple[label: str, confidence: float]`\n",
    "- `label`: One of `['negative', 'neutral', 'positive']`\n",
    "- `confidence`: \n",
    "    - **BERT**: Float between 0.0 - 1.0 representing certainty.\n",
    "    - **GPT-2**: Returns `0.0` (Generative models do not output a single classification probability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BERT Baseline] Input: 'The flight was delayed but the staff was very helpful.'\n",
      "-> Label: positive | Confidence: 0.7588\n",
      "\n",
      "[GPT-2 DPO]     Input: 'The flight was delayed but the staff was very helpful.'\n",
      "-> Label: positive | Confidence: 0.0000\n"
     ]
    }
   ],
   "source": [
    "sample_input = \"The flight was delayed but the staff was very helpful.\"\n",
    "\n",
    "# BERT Prediction\n",
    "label_b, conf_b = bert_api.predict(sample_input)\n",
    "print(f\"[BERT Baseline] Input: '{sample_input}'\")\n",
    "print(f\"-> Label: {label_b} | Confidence: {conf_b:.4f}\")\n",
    "\n",
    "# DPO Prediction\n",
    "label_g, conf_g = dpo_api.predict(sample_input)\n",
    "print(f\"\\n[GPT-2 DPO]     Input: '{sample_input}'\")\n",
    "print(f\"-> Label: {label_g} | Confidence: {conf_g:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Loading Interface\n",
    "The library provides standardized helpers to load and split the specific airline dataset. This ensures that the same data cleaning steps (regex for removing URLs and user mentions) are applied consistently across all experiments.\n",
    "\n",
    "**Function:** `load_airline_data(csv_path: str)`  \n",
    "**Function:** `get_data_splits(df: DataFrame)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully. Total Rows: 14640\n",
      "Label Mapping Used: {'negative': 0, 'neutral': 1, 'positive': 2}\n",
      "Held-out Test Split Size: 1464 samples\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Attempt to load data if file exists locally\n",
    "    # This function automatically applies text cleaning and label mapping\n",
    "    df, label_map = trl_utils.load_airline_data(\"./data/Tweets.csv\")\n",
    "    print(f\"Data loaded successfully. Total Rows: {df.shape[0]}\")\n",
    "    print(f\"Label Mapping Used: {label_map}\")\n",
    "    \n",
    "    # Split the data into Train/Val/Test\n",
    "    train, val, test = trl_utils.get_data_splits(df)\n",
    "    print(f\"Held-out Test Split Size: {len(test)} samples\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"⚠️ Note: 'Tweets.csv' not found. Data loading API requires the dataset file to be present in the root directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
